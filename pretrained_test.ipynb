{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "\n",
    "# Load pre-trained model tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Encode input text\\ninput_text = \"Today the whether is\"\\ninput_ids = tokenizer.encode(input_text, return_tensors=\\'pt\\').to(device)\\n\\n# Check if pad_token_id is None and handle it\\npad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\\nattention_mask = input_ids.ne(pad_token_id).float()\\n\\n# Generate text with adjusted parameters\\noutput = model.generate(\\n    input_ids,\\n    attention_mask=attention_mask,\\n    max_length=1000,\\n    num_return_sequences=1,\\n    do_sample=True,           # Enable sampling\\n    top_k=50,                 # Top-k sampling\\n    top_p=0.95,               # Top-p sampling\\n    temperature=0.7,          # Temperature\\n    repetition_penalty=1.2,   # Penalty for repetition\\n    pad_token_id=pad_token_id\\n)\\n\\n# Decode and print the generated text\\ngenerated_text = tokenizer.decode(output[0], skip_special_tokens=True)\\nprint(generated_text)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Encode input text\n",
    "input_text = \"Today the whether is\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "\n",
    "# Check if pad_token_id is None and handle it\n",
    "pad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "attention_mask = input_ids.ne(pad_token_id).float()\n",
    "\n",
    "# Generate text with adjusted parameters\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=1000,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,           # Enable sampling\n",
    "    top_k=50,                 # Top-k sampling\n",
    "    top_p=0.95,               # Top-p sampling\n",
    "    temperature=0.7,          # Temperature\n",
    "    repetition_penalty=1.2,   # Penalty for repetition\n",
    "    pad_token_id=pad_token_id\n",
    ")\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words: {'science': ['astronomy', 'atom', 'biology', 'cell', 'chemical', 'chemistry', 'climate', 'control', 'data', 'electricity', 'element', 'energy', 'evolution', 'experiment', 'fact', 'flask', 'fossil', 'funnel', 'genetics', 'gravity', 'hypothesis', 'lab', 'laboratory', 'laws', 'mass', 'matter', 'measure', 'microscope', 'mineral', 'molecule', 'motion', 'observe', 'organism', 'particle', 'phase', 'physics', 'research', 'scale', 'science', 'scientist', 'telescope', 'temperature', 'theory', 'tissue', 'variable', 'volume', 'weather', 'weigh'], 'legal': ['affidavit', 'allegation', 'appeal', 'appearance', 'argument', 'arrest', 'assault', 'attorney', 'bail', 'bankrupt', 'bankruptcy', 'bar', 'bench', 'warrant', 'bond', 'booking', 'capital', 'crime', 'case', 'chambers', 'claim', 'complainant', 'complaint', 'confess', 'confession', 'constitution', 'constitutional', 'contract', 'counsel', 'court', 'custody', 'damages', 'decree', 'defendant', 'defense', 'deposition', 'discovery', 'equity', 'estate', 'ethics', 'evidence', 'examination', 'family', 'law', 'felony', 'file', 'fraud', 'grievance', 'guardian', 'guilty', 'hearing', 'immunity', 'incarceration', 'incompetent', 'indictment', 'injunction', 'innocent', 'instructions', 'jail', 'judge', 'judiciary', 'jurisdiction', 'jury', 'justice', 'law', 'lawsuit', 'lawyer', 'legal', 'legislation', 'liable', 'litigation', 'manslaughter', 'mediation', 'minor', 'misdemeanor', 'moot', 'murder', 'negligence', 'oath', 'objection', 'opinion', 'order', 'ordinance', 'pardon', 'parole', 'party', 'perjury', 'petition', 'plaintiff', 'plea', 'precedent', 'prison', 'probation', 'prosecute', 'prosecutor', 'proxy', 'record', 'redress', 'resolution', 'reverse', 'revoke', 'robbery', 'rules', 'sentence', 'settlement', 'sheriff', 'sidebar', 'standing', 'state', 'statute', 'stay', 'subpoena', 'suit', 'suppress', 'sustain', 'testimony', 'theft', 'title', 'tort', 'transcript', 'trial', 'trust', 'trustee', 'venue', 'verdict', 'waiver', 'warrant', 'will', 'witness', 'writ', 'zoning'], 'military': ['academy', 'advance', 'aircraft', 'ally', 'ammo', 'ammunition', 'armor', 'arms', 'army', 'arrow', 'arsenal', 'artillery', 'attack', 'attention', 'ballistic', 'barracks', 'base', 'battalion', 'battery', 'battle', 'battlefield', 'bomb', 'bombard', 'bombardment', 'brig', 'brigade', 'bullet', 'camouflage', 'camp', 'cannon', 'captain', 'capture', 'carrier', 'casualty', 'catapult', 'cavalry', 'colonel', 'combat', 'command', 'commander', 'commission', 'company', 'conflict', 'conquest', 'convoy', 'corps', 'covert', 'crew', 'decode', 'defeat', 'defend', 'defense', 'destroyer', 'division', 'draft', 'encode', 'enemy', 'engage', 'enlist', 'evacuate', 'explosive', 'fight', 'fire', 'fleet', 'force', 'formation', 'fort', 'front', 'garrison', 'general', 'grenade', 'grunt', 'guerrilla', 'gun', 'headquarters', 'helmet', 'honor', 'hospital', 'infantry', 'injury', 'intelligence', 'invade', 'invasion', 'jet', 'kill', 'leave', 'lieutenant', 'major', 'maneuver', 'marines', 'MIA', 'mid', 'military', 'mine', 'missile', 'mortar', 'navy', 'neutral', 'offense', 'officer', 'ordinance', 'parachute', 'peace', 'plane', 'platoon', 'private', 'radar', 'rank', 'recruit', 'regiment', 'rescue', 'reserves', 'retreat', 'ribbon', 'sabotage', 'sailor', 'salute', 'section', 'sergeant', 'service', 'shell', 'shoot', 'shot', 'siege', 'sniper', 'soldier', 'spear', 'specialist', 'squad', 'squadron', 'staff', 'submarine', 'surrender', 'tactical', 'tactics', 'tank', 'torpedo', 'troops', 'truce', 'uniform', 'unit', 'veteran', 'volley', 'war', 'warfare', 'warrior', 'weapon', 'win', 'wound'], 'religion': ['Absolute', 'Affect', 'Aid', 'Angel', 'Anthem', 'Apostle', 'Archangel', 'Archbishop', 'Balance', 'Ban', 'Belief', 'Benefit', 'Bible', 'Bishop', 'Bless', 'Blessing', 'Bliss', 'Bond', 'Bow', 'Buddhism', 'Canon', 'Cantor', 'Cathedral', 'Celestial', 'Chapel', 'Charity', 'Choice', 'Christianity', 'Church', 'Comfort', 'Community', 'Conflict', 'Connection', 'Conquest', 'Conservative', 'Control', 'Conversion', 'Convert', 'Core', 'Counsel', 'Courage', 'Covenant', 'Creative', 'Creator', 'Creed', 'Cross', 'Crusade', 'Darkness', 'Decision', 'Deity', 'Destiny', 'Devil', 'Disciple', 'Discipline', 'Discussion                                                                                                                                                                                                                          [128/1838]', 'Divine', 'Divinity', 'Doctrine', 'Duty', 'Effect', 'Elder', 'Energy', 'Essence', 'Eternal', 'Ethics', 'Event', 'Evidence', 'Exile', 'Exodus', 'Faith', 'Family', 'Fate', 'Father', 'Favor', 'Fundamental', 'Gift', 'Glory', 'God', 'Gospel', 'Grace', 'Growth', 'Guru', 'Habit', 'Hallow', 'Halo', 'Happiness', 'Harmony', 'Healing', 'Heaven', 'Hebrew', 'Holy', 'Honor', 'Hope', 'Host', 'Humane', 'Immortal', 'Influence', 'Insight', 'Instruction', 'Issue', 'Jesuit', 'Jesus', 'Joy', 'Judaism', 'Judgment', 'Justice', 'Karma', 'Keen', 'Keystone', 'Kingdom                                                                                                                                                                                                                              [73/1838]', 'Latin', 'Life', 'Light', 'Love', 'Loving', 'Marriage', 'Meaning', 'Mercy', 'Messiah', 'Minister', 'Miracle', 'Mission', 'Mortal', 'Mosque', 'Movement', 'Music', 'Mystery', 'Nature', 'Nun', 'Official', 'Oracle', 'Order', 'Organ', 'Orthodox', 'Outlook', 'Pacific', 'Pagan', 'Parish', 'Participation', 'Pastor', 'Patriarch', 'Peace', 'Perception', 'Personal', 'Perspective', 'Petition', 'Pilgrim', 'Politics', 'Power', 'Practice', 'Prayer', 'Prelude', 'Presence', 'Priest', 'Principle', 'Privacy', 'Prophet', 'Protection', 'Purpose', 'Query', 'Quest', 'Question', 'Quiet', 'Radiant', 'Radical                                                                                                                                                                                                                              [18/1838]', 'Rally', 'Rebirth', 'Redemption', 'Refuge', 'Relationship', 'Relative', 'Religion', 'Religious', 'Revelation', 'Ritual', 'Role', 'Sacrament', 'Sacred', 'Sacrifice', 'Sage', 'Saint', 'Salvation', 'Sanctuary', 'Savior', 'Scripture', 'Scriptures', 'Sect', 'Security', 'Sense', 'Serious', 'Serve', 'Service', 'Sharia', 'Shepherd', 'Shrine', 'Silence', 'Sin', 'Society', 'Soul', 'Source', 'Spirit', 'Spiritual', 'Split', 'Statue', 'Sunday', 'Support', 'Supreme', 'Teaching', 'Temple', 'Tests', 'Text', 'Torah', 'Tradition', 'Traditional', 'Trust', 'Unique', 'Unity', 'Unknown', 'Value', 'Vanity', 'Virtue', 'Vision', 'Voice', 'Voices', 'Watch', 'Weight', 'Whole', 'Wisdom', 'Wonder', 'Yang', 'Yin', 'Zeal'], 'computers': ['algorithm                                                                                                                                                                                                                           [126/1852]', 'analog', 'app', 'application', 'array', 'backup', 'bandwidth', 'binary', 'bit', 'bite', 'blog', 'blogger', 'bookmark', 'boot', 'broadband', 'browser', 'buffer', 'bug', 'bus', 'byte', 'cache', 'caps', 'captcha', 'CD', 'client', 'command', 'compile', 'compress', 'computer', 'configure', 'cookie', 'copy', 'CPU', 'dashboard', 'data', 'database', 'debug', 'delete', 'desktop', 'development', 'digital', 'disk', 'document', 'domain', 'dot', 'download', 'drag', 'dynamic', 'email', 'encrypt', 'encryption', 'enter', 'FAQ', 'file', 'firewall', 'firmware                                                                                                                                                                                                                             [71/1852]', 'flaming', 'flash', 'folder', 'font', 'format', 'frame', 'graphics', 'hack', 'hacker', 'hardware', 'home', 'host', 'html', 'icon', 'inbox', 'integer', 'interface', 'Internet', 'IP', 'iteration', 'Java', 'joystick', 'kernel', 'key', 'keyboard', 'keyword', 'laptop', 'link', 'Linux', 'logic', 'login', 'lurking', 'Macintosh', 'macro', 'malware', 'media', 'memory', 'mirror', 'modem', 'monitor', 'motherboard', 'mouse', 'multimedia', 'net', 'network', 'node', 'offline', 'online', 'OS', 'option', 'output', 'page', 'password', 'paste', 'path', 'piracy', 'pirate', 'platform', 'podcast', 'portal', 'print', 'printer', 'privacy', 'process', 'program', 'programmer', 'protocol', 'RAM', 'reboot', 'resolution', 'restore', 'ROM', 'root', 'router', 'runtime', 'save', 'scan', 'scanner', 'screen', 'screenshot', 'script', 'scroll', 'security', 'server', 'shell', 'shift', 'snapshot', 'software', 'spam', 'spreadsheet', 'storage', 'surf', 'syntax', 'table', 'tag', 'template', 'thread', 'toolbar', 'trash', 'undo', 'Unix', 'upload', 'URL', 'user', 'UI', 'username', 'utility', 'version', 'virtual', 'virus', 'web', 'website', 'widget', 'wiki', 'window', 'Windows', 'wireless', 'worm', 'XML', 'Zip'], 'politics': ['affirm', 'appropriation', 'aristocracy', 'authoritarian', 'authority', 'authorization', 'brief', 'capitalism', 'communism', 'constitution', 'conservatism', 'court', 'deficit', 'diplomacy', 'direct', 'democracy', 'equality', 'exports', 'fascism', 'federation', 'government', 'ideology', 'imports', 'initiative', 'legislature', 'legitimacy', 'liberalism', 'liberty', 'majority', 'order', 'political', 'culture', 'politics', 'power', 'primary', 'property', 'ratification', 'recall', 'referendum', 'republic', 'socialism', 'state', 'subsidy', 'tariff', 'imports', 'tax', 'totalitarian'], 'space': ['planet', 'galaxy', 'space', 'universe', 'orbit', 'spacecraft', 'earth', 'moon', 'comet', 'star', 'astronaut', 'aerospace', 'asteroid', 'spaceship', 'starship', 'galactic', 'satellite', 'meteor'], 'positive_words': ['abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation', 'accolade', 'accolades', 'accommodative', 'accomodative', 'accomplish', 'accomplished', 'accomplishment', 'accomplishments', 'accurate', 'accurately', 'achievable', 'achievement', 'achievements', 'achievible', 'acumen', 'adaptable', 'adaptive', 'adequate', 'adjustable', 'admirable', 'admirably', 'admiration', 'admire', 'admirer', 'admiring', 'admiringly', 'adorable', 'adore', 'adored', 'adorer', 'adoring', 'adoringly', 'adroit', 'adroitly', 'adulate', 'adulation', 'adulatory', 'advanced', 'advantage', 'advantageous', 'advantageously', 'advantages', 'adventuresome', 'adventurous', 'advocate', 'advocated', 'advocates', 'affability', 'affable', 'affably', 'affectation', 'affection', 'affectionate', 'affinity', 'affirm', 'affirmation', 'affirmative', 'affluence', 'affluent', 'afford', 'affordable', 'affordably', 'afordable', 'agile', 'agilely', 'agility', 'agreeable', 'agreeableness', 'agreeably', 'all-around', 'alluring', 'alluringly', 'altruistic', 'altruistically', 'amaze', 'amazed', 'amazement', 'amazes', 'amazing', 'amazingly', 'ambitious', 'ambitiously', 'ameliorate', 'amenable', 'amenity', 'amiability', 'amiabily', 'amiable', 'amicability', 'amicable', 'amicably', 'amity', 'ample', 'amply', 'amuse', 'amusing', 'amusingly', 'angel', 'angelic', 'apotheosis', 'appeal', 'appealing', 'applaud', 'appreciable', 'appreciate', 'appreciated', 'appreciates', 'appreciative', 'appreciatively', 'appropriate', 'approval', 'approve', 'ardent', 'ardently', 'ardor', 'articulate', 'aspiration', 'aspirations', 'aspire', 'assurance', 'assurances', 'assure', 'assuredly', 'assuring', 'astonish', 'astonished', 'astonishing', 'astonishingly', 'astonishment', 'astound', 'astounded', 'astounding', 'astoundingly', 'astutely', 'attentive', 'attraction', 'attractive', 'attractively', 'attune', 'audible', 'audibly', 'auspicious', 'authentic', 'authoritative', 'autonomous', 'available', 'aver', 'avid', 'avidly', 'award', 'awarded', 'awards', 'awe', 'awed', 'awesome', 'awesomely', 'awesomeness', 'awestruck', 'awsome', 'backbone', 'balanced', 'bargain', 'beauteous', 'beautiful', 'beautifullly', 'beautifully', 'beautify', 'beauty', 'beckon', 'beckoned', 'beckoning', 'beckons', 'believable', 'believeable', 'beloved', 'benefactor', 'beneficent', 'beneficial', 'beneficially', 'beneficiary', 'benefit', 'benefits', 'benevolence', 'benevolent', 'benifits', 'best', 'best-known', 'best-performing', 'best-selling', 'better', 'better-known', 'better-than-expected', 'beutifully', 'blameless', 'bless', 'blessing', 'bliss', 'blissful', 'blissfully', 'blithe', 'blockbuster', 'bloom', 'blossom', 'bolster', 'bonny', 'bonus', 'bonuses', 'boom', 'booming', 'boost', 'boundless', 'bountiful', 'brainiest', 'brainy', 'brand-new', 'brave', 'bravery', 'bravo', 'breakthrough', 'breakthroughs', 'breathlessness', 'breathtaking', 'breathtakingly', 'breeze', 'bright', 'brighten', 'brighter', 'brightest', 'brilliance', 'brilliances', 'brilliant', 'brilliantly', 'brisk', 'brotherly', 'bullish', 'buoyant', 'cajole', 'calm', 'calming', 'calmness', 'capability', 'capable', 'capably', 'captivate', 'captivating', 'carefree', 'cashback', 'cashbacks', 'catchy', 'celebrate', 'celebrated', 'celebration', 'celebratory', 'champ', 'champion', 'charisma', 'charismatic', 'charitable', 'charm', 'charming', 'charmingly', 'chaste', 'cheaper', 'cheapest', 'cheer', 'cheerful', 'cheery', 'cherish', 'cherished', 'cherub', 'chic', 'chivalrous', 'chivalry', 'civility', 'civilize', 'clarity', 'classic', 'classy', 'clean', 'cleaner', 'cleanest', 'cleanliness', 'cleanly', 'clear', 'clear-cut', 'cleared', 'clearer', 'clearly', 'clears', 'clever', 'cleverly', 'cohere', 'coherence', 'coherent', 'cohesive', 'colorful', 'comely', 'comfort', 'comfortable', 'comfortably', 'comforting', 'comfy', 'commend', 'commendable', 'commendably', 'commitment', 'commodious', 'compact', 'compactly', 'compassion', 'compassionate', 'compatible', 'competitive', 'complement', 'complementary', 'complemented', 'complements', 'compliant', 'compliment', 'complimentary', 'comprehensive', 'conciliate', 'conciliatory', 'concise', 'confidence', 'confident', 'congenial', 'congratulate', 'congratulation', 'congratulations', 'congratulatory', 'conscientious', 'considerate', 'consistent', 'consistently', 'constructive', 'consummate', 'contentment', 'continuity', 'contrasty', 'contribution', 'convenience', 'convenient', 'conveniently', 'convience', 'convienient', 'convient', 'convincing', 'convincingly', 'cool', 'coolest', 'cooperative', 'cooperatively', 'cornerstone', 'correct', 'correctly', 'cost-effective', 'cost-saving', 'counter-attack', 'counter-attacks', 'courage', 'courageous', 'courageously', 'courageousness', 'courteous', 'courtly', 'covenant', 'cozy', 'creative', 'credence', 'credible', 'crisp', 'crisper', 'cure', 'cure-all', 'cushy', 'cute', 'cuteness', 'danke', 'danken', 'daring', 'daringly', 'darling', 'dashing', 'dauntless', 'dawn', 'dazzle', 'dazzled', 'dazzling', 'dead-cheap', 'dead-on', 'decency', 'decent', 'decisive', 'decisiveness', 'dedicated', 'defeat', 'defeated', 'defeating', 'defeats', 'defender', 'deference', 'deft', 'deginified', 'delectable', 'delicacy', 'delicate', 'delicious', 'delight', 'delighted', 'delightful', 'delightfully', 'delightfulness', 'dependable', 'dependably', 'deservedly', 'deserving', 'desirable', 'desiring', 'desirous', 'destiny', 'detachable', 'devout', 'dexterous', 'dexterously', 'dextrous', 'dignified', 'dignify', 'dignity', 'diligence', 'diligent', 'diligently', 'diplomatic', 'dirt-cheap', 'distinction', 'distinctive', 'distinguished', 'diversified', 'divine', 'divinely', 'dominate', 'dominated', 'dominates', 'dote', 'dotingly', 'doubtless', 'dreamland', 'dumbfounded', 'dumbfounding', 'dummy-proof', 'durable', 'dynamic', 'eager', 'eagerly', 'eagerness', 'earnest', 'earnestly', 'earnestness', 'ease', 'eased', 'eases', 'easier', 'easiest', 'easiness', 'easing', 'easy', 'easy-to-use', 'easygoing', 'ebullience', 'ebullient', 'ebulliently', 'ecenomical', 'economical', 'ecstasies', 'ecstasy', 'ecstatic', 'ecstatically', 'edify', 'educated', 'effective', 'effectively', 'effectiveness', 'effectual', 'efficacious', 'efficient', 'efficiently', 'effortless', 'effortlessly', 'effusion', 'effusive', 'effusively', 'effusiveness', 'elan', 'elate', 'elated', 'elatedly', 'elation', 'electrify', 'elegance', 'elegant', 'elegantly', 'elevate', 'elite', 'eloquence', 'eloquent', 'eloquently', 'embolden', 'eminence', 'eminent', 'empathize', 'empathy', 'empower', 'empowerment', 'enchant', 'enchanted', 'enchanting', 'enchantingly', 'encourage', 'encouragement', 'encouraging', 'encouragingly', 'endear', 'endearing', 'endorse', 'endorsed', 'endorsement', 'endorses', 'endorsing', 'energetic', 'energize', 'energy-efficient', 'energy-saving', 'engaging', 'engrossing', 'enhance', 'enhanced', 'enhancement', 'enhances', 'enjoy', 'enjoyable', 'enjoyably', 'enjoyed', 'enjoying', 'enjoyment', 'enjoys', 'enlighten', 'enlightenment', 'enliven', 'ennoble', 'enough', 'enrapt', 'enrapture', 'enraptured', 'enrich', 'enrichment', 'enterprising', 'entertain', 'entertaining', 'entertains', 'enthral', 'enthrall', 'enthralled', 'enthuse', 'enthusiasm', 'enthusiast', 'enthusiastic', 'enthusiastically', 'entice', 'enticed', 'enticing', 'enticingly', 'entranced', 'entrancing', 'entrust', 'enviable', 'enviably', 'envious', 'enviously', 'enviousness', 'envy', 'equitable', 'ergonomical', 'err-free', 'erudite', 'ethical', 'eulogize', 'euphoria', 'euphoric', 'euphorically', 'evaluative', 'evenly', 'eventful', 'everlasting', 'evocative', 'exalt', 'exaltation', 'exalted', 'exaltedly', 'exalting', 'exaltingly', 'examplar', 'examplary', 'excallent', 'exceed', 'exceeded', 'exceeding', 'exceedingly', 'exceeds', 'excel', 'exceled', 'excelent', 'excellant', 'excelled', 'excellence', 'excellency', 'excellent', 'excellently', 'excels', 'exceptional', 'exceptionally', 'excite', 'excited', 'excitedly', 'excitedness', 'excitement', 'excites', 'exciting', 'excitingly', 'exellent', 'exemplar', 'exemplary', 'exhilarate', 'exhilarating', 'exhilaratingly', 'exhilaration', 'exonerate', 'expansive', 'expeditiously', 'expertly', 'exquisite', 'exquisitely', 'extol', 'extoll', 'extraordinarily', 'extraordinary', 'exuberance', 'exuberant', 'exuberantly', 'exult', 'exultant', 'exultation', 'exultingly', 'eye-catch', 'eye-catching', 'eyecatch', 'eyecatching', 'fabulous', 'fabulously', 'facilitate', 'fair', 'fairly', 'fairness', 'faith', 'faithful', 'faithfully', 'faithfulness', 'fame', 'famed', 'famous', 'famously', 'fancier', 'fancinating', 'fancy', 'fanfare', 'fans', 'fantastic', 'fantastically', 'fascinate', 'fascinating', 'fascinatingly', 'fascination', 'fashionable', 'fashionably', 'fast', 'fast-growing', 'fast-paced', 'faster', 'fastest', 'fastest-growing', 'faultless', 'fav', 'fave', 'favor', 'favorable', 'favored', 'favorite', 'favorited', 'favour', 'fearless', 'fearlessly', 'feasible', 'feasibly', 'feat', 'feature-rich', 'fecilitous', 'feisty', 'felicitate', 'felicitous', 'felicity', 'fertile', 'fervent', 'fervently', 'fervid', 'fervidly', 'fervor', 'festive', 'fidelity', 'fiery', 'fine', 'fine-looking', 'finely', 'finer', 'finest', 'firmer', 'first-class', 'first-in-class', 'first-rate', 'flashy', 'flatter', 'flattering', 'flatteringly', 'flawless', 'flawlessly', 'flexibility', 'flexible', 'flourish', 'flourishing', 'fluent', 'flutter', 'fond', 'fondly', 'fondness', 'foolproof', 'foremost', 'foresight', 'formidable', 'fortitude', 'fortuitous', 'fortuitously', 'fortunate', 'fortunately', 'fortune', 'fragrant', 'free', 'freed', 'freedom', 'freedoms', 'fresh', 'fresher', 'freshest', 'friendliness', 'friendly', 'frolic', 'frugal', 'fruitful', 'ftw', 'fulfillment', 'fun', 'futurestic', 'futuristic', 'gaiety', 'gaily', 'gain', 'gained', 'gainful', 'gainfully', 'gaining', 'gains', 'gallant', 'gallantly', 'galore', 'geekier', 'geeky', 'gem', 'gems', 'generosity', 'generous', 'generously', 'genial', 'genius', 'gentle', 'gentlest', 'genuine', 'gifted', 'glad', 'gladden', 'gladly', 'gladness', 'glamorous', 'glee', 'gleeful', 'gleefully', 'glimmer', 'glimmering', 'glisten', 'glistening', 'glitter', 'glitz', 'glorify', 'glorious', 'gloriously', 'glory', 'glow', 'glowing', 'glowingly', 'god-given', 'god-send', 'godlike', 'godsend', 'gold', 'golden', 'good', 'goodly', 'goodness', 'goodwill', 'goood', 'gooood', 'gorgeous', 'gorgeously', 'grace', 'graceful', 'gracefully', 'gracious', 'graciously', 'graciousness', 'grand', 'grandeur', 'grateful', 'gratefully', 'gratification', 'gratified', 'gratifies', 'gratify', 'gratifying', 'gratifyingly', 'gratitude', 'great', 'greatest', 'greatness', 'grin', 'groundbreaking', 'guarantee', 'guidance', 'guiltless', 'gumption', 'gush', 'gusto', 'gutsy', 'hail', 'halcyon', 'hale', 'hallmark', 'hallmarks', 'hallowed', 'handier', 'handily', 'hands-down', 'handsome', 'handsomely', 'handy', 'happier', 'happily', 'happiness', 'happy', 'hard-working', 'hardier', 'hardy', 'harmless', 'harmonious', 'harmoniously', 'harmonize', 'harmony', 'headway', 'heal', 'healthful', 'healthy', 'hearten', 'heartening', 'heartfelt', 'heartily', 'heartwarming', 'heaven', 'heavenly', 'helped', 'helpful', 'helping', 'hero', 'heroic', 'heroically', 'heroine', 'heroize', 'heros', 'high-quality', 'high-spirited', 'hilarious', 'holy', 'homage', 'honest', 'honesty', 'honor', 'honorable', 'honored', 'honoring', 'hooray', 'hopeful', 'hospitable', 'hot', 'hotcake', 'hotcakes', 'hottest', 'hug', 'humane', 'humble', 'humility', 'humor', 'humorous', 'humorously', 'humour', 'humourous', 'ideal', 'idealize', 'ideally', 'idol', 'idolize', 'idolized', 'idyllic', 'illuminate', 'illuminati', 'illuminating', 'illumine', 'illustrious', 'ilu', 'imaculate', 'imaginative', 'immaculate', 'immaculately', 'immense', 'impartial', 'impartiality', 'impartially', 'impassioned', 'impeccable', 'impeccably', 'important', 'impress', 'impressed', 'impresses', 'impressive', 'impressively', 'impressiveness', 'improve', 'improved', 'improvement', 'improvements', 'improves', 'improving', 'incredible', 'incredibly', 'indebted', 'individualized', 'indulgence', 'indulgent', 'industrious', 'inestimable', 'inestimably', 'inexpensive', 'infallibility', 'infallible', 'infallibly', 'influential', 'ingenious', 'ingeniously', 'ingenuity', 'ingenuous', 'ingenuously', 'innocuous', 'innovation', 'innovative', 'inpressed', 'insightful', 'insightfully', 'inspiration', 'inspirational', 'inspire', 'inspiring', 'instantly', 'instructive', 'instrumental', 'integral', 'integrated', 'intelligence', 'intelligent', 'intelligible', 'interesting', 'interests', 'intimacy', 'intimate', 'intricate', 'intrigue', 'intriguing', 'intriguingly', 'intuitive', 'invaluable', 'invaluablely', 'inventive', 'invigorate', 'invigorating', 'invincibility', 'invincible', 'inviolable', 'inviolate', 'invulnerable', 'irreplaceable', 'irreproachable', 'irresistible', 'irresistibly', 'issue-free', 'jaw-droping', 'jaw-dropping', 'jollify', 'jolly', 'jovial', 'joy', 'joyful', 'joyfully', 'joyous', 'joyously', 'jubilant', 'jubilantly', 'jubilate', 'jubilation', 'jubiliant', 'judicious', 'justly', 'keen', 'keenly', 'keenness', 'kid-friendly', 'kindliness', 'kindly', 'kindness', 'knowledgeable', 'kudos', 'large-capacity', 'laud', 'laudable', 'laudably', 'lavish', 'lavishly', 'law-abiding', 'lawful', 'lawfully', 'lead', 'leading', 'leads', 'lean', 'led', 'legendary', 'leverage', 'levity', 'liberate', 'liberation', 'liberty', 'lifesaver', 'light-hearted', 'lighter', 'likable', 'like', 'liked', 'likes', 'liking', 'lionhearted', 'lively', 'logical', 'long-lasting', 'lovable', 'lovably', 'love', 'loved', 'loveliness', 'lovely', 'lover', 'loves', 'loving', 'low-cost', 'low-price', 'low-priced', 'low-risk', 'lower-priced', 'loyal', 'loyalty', 'lucid', 'lucidly', 'luck', 'luckier', 'luckiest', 'luckiness', 'lucky', 'lucrative', 'luminous', 'lush', 'luster', 'lustrous', 'luxuriant', 'luxuriate', 'luxurious', 'luxuriously', 'luxury', 'lyrical', 'magic', 'magical', 'magnanimous', 'magnanimously', 'magnificence', 'magnificent', 'magnificently', 'majestic', 'majesty', 'manageable', 'maneuverable', 'marvel', 'marveled', 'marvelled', 'marvellous', 'marvelous', 'marvelously', 'marvelousness', 'marvels', 'master', 'masterful', 'masterfully', 'masterpiece', 'masterpieces', 'masters', 'mastery', 'matchless', 'mature', 'maturely', 'maturity', 'meaningful', 'memorable', 'merciful', 'mercifully', 'mercy', 'merit', 'meritorious', 'merrily', 'merriment', 'merriness', 'merry', 'mesmerize', 'mesmerized', 'mesmerizes', 'mesmerizing', 'mesmerizingly', 'meticulous', 'meticulously', 'mightily', 'mighty', 'mind-blowing', 'miracle', 'miracles', 'miraculous', 'miraculously', 'miraculousness', 'modern', 'modest', 'modesty', 'momentous', 'monumental', 'monumentally', 'morality', 'motivated', 'multi-purpose', 'navigable', 'neat', 'neatest', 'neatly', 'nice', 'nicely', 'nicer', 'nicest', 'nifty', 'nimble', 'noble', 'nobly', 'noiseless', 'non-violence', 'non-violent', 'notably', 'noteworthy', 'nourish', 'nourishing', 'nourishment', 'novelty', 'nurturing', 'oasis', 'obsession', 'obsessions', 'obtainable', 'openly', 'openness', 'optimal', 'optimism', 'optimistic', 'opulent', 'orderly', 'originality', 'outdo', 'outdone', 'outperform', 'outperformed', 'outperforming', 'outperforms', 'outshine', 'outshone', 'outsmart', 'outstanding', 'outstandingly', 'outstrip', 'outwit', 'ovation', 'overjoyed', 'overtake', 'overtaken', 'overtakes', 'overtaking', 'overtook', 'overture', 'pain-free', 'painless', 'painlessly', 'palatial', 'pamper', 'pampered', 'pamperedly', 'pamperedness', 'pampers', 'panoramic', 'paradise', 'paramount', 'pardon', 'passion', 'passionate', 'passionately', 'patience', 'patient', 'patiently', 'patriot', 'patriotic', 'peace', 'peaceable', 'peaceful', 'peacefully', 'peacekeepers', 'peach', 'peerless', 'pep', 'pepped', 'pepping', 'peppy', 'peps', 'perfect', 'perfection', 'perfectly', 'permissible', 'perseverance', 'persevere', 'personages', 'personalized', 'phenomenal', 'phenomenally', 'picturesque', 'piety', 'pinnacle', 'playful', 'playfully', 'pleasant', 'pleasantly', 'pleased', 'pleases', 'pleasing', 'pleasingly', 'pleasurable', 'pleasurably', 'pleasure', 'plentiful', 'pluses', 'plush', 'plusses', 'poetic', 'poeticize', 'poignant', 'poise', 'poised', 'polished', 'polite', 'politeness', 'popular', 'portable', 'posh', 'positive', 'positively', 'positives', 'powerful', 'powerfully', 'praise', 'praiseworthy', 'praising', 'pre-eminent', 'precious', 'precise', 'precisely', 'preeminent', 'prefer', 'preferable', 'preferably', 'prefered', 'preferes', 'preferring', 'prefers', 'premier', 'prestige', 'prestigious', 'prettily', 'pretty', 'priceless', 'pride', 'principled', 'privilege', 'privileged', 'prize', 'proactive', 'problem-free', 'problem-solver', 'prodigious', 'prodigiously', 'prodigy', 'productive', 'productively', 'proficient', 'proficiently', 'profound', 'profoundly', 'profuse', 'profusion', 'progress', 'progressive', 'prolific', 'prominence', 'prominent', 'promise', 'promised', 'promises', 'promising', 'promoter', 'prompt', 'promptly', 'proper', 'properly', 'propitious', 'propitiously', 'pros', 'prosper', 'prosperity', 'prosperous', 'prospros', 'protect', 'protection', 'protective', 'proud', 'proven', 'proves', 'providence', 'proving', 'prowess', 'prudence', 'prudent', 'prudently', 'punctual', 'pure', 'purify', 'purposeful', 'quaint', 'qualified', 'qualify', 'quicker', 'quiet', 'quieter', 'radiance', 'radiant', 'rapid', 'rapport', 'rapt', 'rapture', 'raptureous', 'raptureously', 'rapturous', 'rapturously', 'rational', 'razor-sharp', 'reachable', 'readable', 'readily', 'ready', 'reaffirm', 'reaffirmation', 'realistic', 'realizable', 'reasonable', 'reasonably', 'reasoned', 'reassurance', 'reassure', 'receptive', 'reclaim', 'recomend', 'recommend', 'recommendation', 'recommendations', 'recommended', 'reconcile', 'reconciliation', 'record-setting', 'recover', 'recovery', 'rectification', 'rectify', 'rectifying', 'redeem', 'redeeming', 'redemption', 'refine', 'refined', 'refinement', 'reform', 'reformed', 'reforming', 'reforms', 'refresh', 'refreshed', 'refreshing', 'refund', 'refunded', 'regal', 'regally', 'regard', 'rejoice', 'rejoicing', 'rejoicingly', 'rejuvenate', 'rejuvenated', 'rejuvenating', 'relaxed', 'relent', 'reliable', 'reliably', 'relief', 'relish', 'remarkable', 'remarkably', 'remedy', 'remission', 'remunerate', 'renaissance', 'renewed', 'renown', 'renowned', 'replaceable', 'reputable', 'reputation', 'resilient', 'resolute', 'resound', 'resounding', 'resourceful', 'resourcefulness', 'respect', 'respectable', 'respectful', 'respectfully', 'respite', 'resplendent', 'responsibly', 'responsive', 'restful', 'restored', 'restructure', 'restructured', 'restructuring', 'retractable', 'revel', 'revelation', 'revere', 'reverence', 'reverent', 'reverently', 'revitalize', 'revival', 'revive', 'revives', 'revolutionary', 'revolutionize', 'revolutionized', 'revolutionizes', 'reward', 'rewarding', 'rewardingly', 'rich', 'richer', 'richly', 'richness', 'right', 'righten', 'righteous', 'righteously', 'righteousness', 'rightful', 'rightfully', 'rightly', 'rightness', 'risk-free', 'robust', 'rock-star', 'rock-stars', 'rockstar', 'rockstars', 'romantic', 'romantically', 'romanticize', 'roomier', 'roomy', 'rosy', 'safe', 'safely', 'sagacity', 'sagely', 'saint', 'saintliness', 'saintly', 'salutary', 'salute', 'sane', 'satisfactorily', 'satisfactory', 'satisfied', 'satisfies', 'satisfy', 'satisfying', 'satisified', 'saver', 'savings', 'savior', 'savvy', 'scenic', 'seamless', 'seasoned', 'secure', 'securely', 'selective', 'self-determination', 'self-respect', 'self-satisfaction', 'self-sufficiency', 'self-sufficient', 'sensation', 'sensational', 'sensationally', 'sensations', 'sensible', 'sensibly', 'sensitive', 'serene', 'serenity', 'sexy', 'sharp', 'sharper', 'sharpest', 'shimmering', 'shimmeringly', 'shine', 'shiny', 'significant', 'silent', 'simpler', 'simplest', 'simplified', 'simplifies', 'simplify', 'simplifying', 'sincere', 'sincerely', 'sincerity', 'skill', 'skilled', 'skillful', 'skillfully', 'slammin', 'sleek', 'slick', 'smart', 'smarter', 'smartest', 'smartly', 'smile', 'smiles', 'smiling', 'smilingly', 'smitten', 'smooth', 'smoother', 'smoothes', 'smoothest', 'smoothly', 'snappy', 'snazzy', 'sociable', 'soft', 'softer', 'solace', 'solicitous', 'solicitously', 'solid', 'solidarity', 'soothe', 'soothingly', 'sophisticated', 'soulful', 'soundly', 'soundness', 'spacious', 'sparkle', 'sparkling', 'spectacular', 'spectacularly', 'speedily', 'speedy', 'spellbind', 'spellbinding', 'spellbindingly', 'spellbound', 'spirited', 'spiritual', 'splendid', 'splendidly', 'splendor', 'spontaneous', 'sporty', 'spotless', 'sprightly', 'stability', 'stabilize', 'stable', 'stainless', 'standout', 'state-of-the-art', 'stately', 'statuesque', 'staunch', 'staunchly', 'staunchness', 'steadfast', 'steadfastly', 'steadfastness', 'steadiest', 'steadiness', 'steady', 'stellar', 'stellarly', 'stimulate', 'stimulates', 'stimulating', 'stimulative', 'stirringly', 'straighten', 'straightforward', 'streamlined', 'striking', 'strikingly', 'striving', 'strong', 'stronger', 'strongest', 'stunned', 'stunning', 'stunningly', 'stupendous', 'stupendously', 'sturdier', 'sturdy', 'stylish', 'stylishly', 'stylized', 'suave', 'suavely', 'sublime', 'subsidize', 'subsidized', 'subsidizes', 'subsidizing', 'substantive', 'succeed', 'succeeded', 'succeeding', 'succeeds', 'succes', 'success', 'successes', 'successful', 'successfully', 'suffice', 'sufficed', 'suffices', 'sufficient', 'sufficiently', 'suitable', 'sumptuous', 'sumptuously', 'sumptuousness', 'super', 'superb', 'superbly', 'superior', 'superiority', 'supple', 'support', 'supported', 'supporter', 'supporting', 'supportive', 'supports', 'supremacy', 'supreme', 'supremely', 'supurb', 'supurbly', 'surmount', 'surpass', 'surreal', 'survival', 'survivor', 'sustainability', 'sustainable', 'swank', 'swankier', 'swankiest', 'swanky', 'sweeping', 'sweet', 'sweeten', 'sweetheart', 'sweetly', 'sweetness', 'swift', 'swiftness', 'talent', 'talented', 'talents', 'tantalize', 'tantalizing', 'tantalizingly', 'tempt', 'tempting', 'temptingly', 'tenacious', 'tenaciously', 'tenacity', 'tender', 'tenderly', 'terrific', 'terrifically', 'thank', 'thankful', 'thinner', 'thoughtful', 'thoughtfully', 'thoughtfulness', 'thrift', 'thrifty', 'thrill', 'thrilled', 'thrilling', 'thrillingly', 'thrills', 'thrive', 'thriving', 'thumb-up', 'thumbs-up', 'tickle', 'tidy', 'time-honored', 'timely', 'tingle', 'titillate', 'titillating', 'titillatingly', 'togetherness', 'tolerable', 'toll-free', 'top', 'top-notch', 'top-quality', 'topnotch', 'tops', 'tough', 'tougher', 'toughest', 'traction', 'tranquil', 'tranquility', 'transparent', 'treasure', 'tremendously', 'trendy', 'triumph', 'triumphal', 'triumphant', 'triumphantly', 'trivially', 'trophy', 'trouble-free', 'trump', 'trumpet', 'trust', 'trusted', 'trusting', 'trustingly', 'trustworthiness', 'trustworthy', 'trusty', 'truthful', 'truthfully', 'truthfulness', 'twinkly', 'ultra-crisp', 'unabashed', 'unabashedly', 'unaffected', 'unassailable', 'unbeatable', 'unbiased', 'unbound', 'uncomplicated', 'unconditional', 'undamaged', 'undaunted', 'understandable', 'undisputable', 'undisputably', 'undisputed', 'unencumbered', 'unequivocal', 'unequivocally', 'unfazed', 'unfettered', 'unforgettable', 'unity', 'unlimited', 'unmatched', 'unparalleled', 'unquestionable', 'unquestionably', 'unreal', 'unrestricted', 'unrivaled', 'unselfish', 'unwavering', 'upbeat', 'upgradable', 'upgradeable', 'upgraded', 'upheld', 'uphold', 'uplift', 'uplifting', 'upliftingly', 'upliftment', 'upscale', 'usable', 'useable', 'useful', 'user-friendly', 'user-replaceable', 'valiant', 'valiantly', 'valor', 'valuable', 'variety', 'venerate', 'verifiable', 'veritable', 'versatile', 'versatility', 'vibrant', 'vibrantly', 'victorious', 'victory', 'viewable', 'vigilance', 'vigilant', 'virtue', 'virtuous', 'virtuously', 'visionary', 'vivacious', 'vivid', 'vouch', 'vouchsafe', 'warm', 'warmer', 'warmhearted', 'warmly', 'warmth', 'wealthy', 'welcome', 'well', 'well-backlit', 'well-balanced', 'well-behaved', 'well-being', 'well-bred', 'well-connected', 'well-educated', 'well-established', 'well-informed', 'well-intentioned', 'well-known', 'well-made', 'well-managed', 'well-mannered', 'well-positioned', 'well-received', 'well-regarded', 'well-rounded', 'well-run', 'well-wishers', 'wellbeing', 'whoa', 'wholeheartedly', 'wholesome', 'whooa', 'whoooa', 'wieldy', 'willing', 'willingly', 'willingness', 'win', 'windfall', 'winnable', 'winner', 'winners', 'winning', 'wins', 'wisdom', 'wise', 'wisely', 'witty', 'won', 'wonder', 'wonderful', 'wonderfully', 'wonderous', 'wonderously', 'wonders', 'wondrous', 'woo', 'work', 'workable', 'worked', 'works', 'world-famous', 'worth', 'worth-while', 'worthiness', 'worthwhile', 'worthy', 'wow', 'wowed', 'wowing', 'wows', 'yay', 'youthful', 'zeal', 'zenith', 'zest', 'zippy'], 'fantasy': ['beast', 'Cerberus', 'demon', 'dragon', 'fairy', 'Frankenstein', 'ghost', 'Godzilla', 'giant', 'horror', 'hydra', 'imp', 'monster', 'mummy', 'ogre', 'orc', 'savage', 'spirit', 'sprite', 'titan', 'troll', 'undead', 'unicorn', 'vampire', 'witch', 'zombie'], 'kitchen': ['aluminum foil', 'apron', 'baking dish', 'basket', 'batter', 'beater', 'blender', 'boil', 'bottle', 'bottle opener', 'bowl', 'bread basket', 'broiler', 'broom', 'bun warmer', 'bundt pan', 'butter dish', 'cabinet', 'caddy', 'cake pan', 'cake stand', 'can', 'can opener', 'carafe', 'casserole', 'cast iron pan', 'china', 'chop', 'chopsticks', 'cleanser', 'coffee grinder', 'coffee maker', 'coffee mill', 'colander', 'cook', 'cookbook', 'cooker', 'cookie cutter', 'cookie sheet', 'corn pick', 'counter', 'creamer', 'crock-pot', 'cup', 'cupboard', 'custard cup', 'cutlery', 'cutting board', 'decanter', 'dish', 'dish rack', 'dish soap', 'dish towel', 'dishwasher', 'dough', 'Dutch oven', 'egg beater', 'egg timer', 'espresso machine', 'flatware', 'flour sifter', 'fondue set', 'food', 'food processor', 'fork', 'freezer', 'fruit bowl', 'fryer', 'frying pan', 'garbage bag', 'garbage can', 'garbage compactor', 'garbage disposal', 'garlic press', 'glasses', 'grater', 'gravy boat', 'griddle', 'grill', 'grinder', 'honey dipper', 'honey pot', 'hot plate', 'ice box', 'ice bucket', 'ice cream maker', 'ice cream scoop', 'ice cube tray', 'ice pick', 'iron skillet', 'island', 'jarjug', 'juice glass', 'juicer', 'kettle', 'kitchen', 'kitchen island', 'knife', 'knife sharpener', 'ladle', 'leftovers', 'lid', 'marinate', 'masher', 'measuring cup', 'measuring spoons', 'meat grinder', 'meat tenderizer', 'meat thermometer', 'microwave oven', 'mixer', 'mixing bowl', 'mold', 'mop', 'mortar and pestle', 'muffin pan', 'mug', 'napkin', 'nesting bowls', 'nut cracker', 'nut pick', 'opener', 'oven', 'oven mitt', 'pan', 'paper towels', 'pepper grinder', 'pepper mill', 'pepper shaker', 'percolator', 'pestle', 'pie plate', 'pitcher', 'pizza cutter', 'pizza pan', 'pizza wheel', 'placemat', 'plastic bags', 'plastic wrap', 'plate', 'platter', 'popcorn popper', 'pot', 'potato masher', 'potholder', 'poultry shears', 'pressure cooker', 'quiche pan', 'ramekin', 'range', 'reamer', 'recipe', 'refrigerator', 'rice cooker', 'roaster', 'roasting pan', 'rolling pin', 'salad bowl', 'salad spinner', 'salt shaker', 'sauce boat', 'sauce pan', 'saucer', 'serving pieces', 'serving platter', 'shears', 'shelves', 'sieve', 'sifter', 'silverware', 'sink', 'skewers', 'skillet', 'slicer', 'slow cooker', 'soap', 'soup bowl', 'spatula', 'spice jar', 'spices', 'sponge', 'spoon', 'steak knife', 'steamer', 'steel wool', 'stew pot', 'stove', 'sugar bowl', 'sugar', 'sifter', 'table', 'tablecloth', 'tablespoon', 'tea cup', 'tea infuser', 'teapot', 'tea spoon', 'thermometer', 'timer', 'tin', 'toaster', 'toaster oven', 'tongs', 'trash bags', 'trash can', 'tray', 'trivet', 'tumbler', 'tureen', 'utensils', 'vegetable bin', 'vegetable brush', 'vegetable peeler', 'waffle iron', 'waste basket', 'waxed paper', 'whip', 'whisk', 'whisk broom', 'wok', 'yogurt maker', 'zester']}\n"
     ]
    }
   ],
   "source": [
    "def create_bag_of_words(folder_path):\n",
    "    bag_of_words = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        if os.path.isfile(file_path) and filename.endswith('.txt'):\n",
    "            topic = os.path.splitext(filename)[0]\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                words = file.read().splitlines()\n",
    "                bag_of_words[topic] = words\n",
    "    \n",
    "    return bag_of_words\n",
    "\n",
    "folder_path = 'wordlists'\n",
    "bow = create_bag_of_words(folder_path)\n",
    "\n",
    "print(\"Bag of Words:\", bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_classification(text, topic_dict):\n",
    "    # Tokenize (split by space, lowercase everything)\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    # Count occurrences\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Score each topic by summing occurrences\n",
    "    scores = {topic: sum(word_counts[word] for word in words_set) for topic, words_set in topic_dict.items()}\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'science': 11, 'legal': 0, 'military': 0, 'religion': 0, 'computers': 1, 'politics': 0, 'space': 0, 'positive_words': 0, 'fantasy': 0, 'kitchen': 0}\n",
      "{'science': 0, 'legal': 0, 'military': 2, 'religion': 0, 'computers': 0, 'politics': 0, 'space': 0, 'positive_words': 4, 'fantasy': 0, 'kitchen': 0}\n"
     ]
    }
   ],
   "source": [
    "text1 = \"climate control data electricity element energy evolution experiment fact flask fossil\"\n",
    "text2 = \"The military has deployed advanced drone technology to enhance surveillance and reconnaissance missions, providing real-time intelligence and improving strategic decision-making.\"\n",
    "\n",
    "print(bag_of_words_classification(text1, bow))\n",
    "print(bag_of_words_classification(text2, bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWAttributeModel:\n",
    "    def __init__(self, topics_dict, tokenizer, vocab_size=50257):\n",
    "        \"\"\"\n",
    "        Initialize the BoWAttributeModel with a dictionary of topics.\n",
    "\n",
    "        :param topics_dict: Dictionary where keys are topics and values are lists of words.\n",
    "        :param tokenizer: Tokenizer to convert words to token IDs.\n",
    "        :param vocab_size: Size of the vocabulary.\n",
    "        \"\"\"\n",
    "        self.topics_dict = topics_dict\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.topic_masks = self._build_topic_masks()\n",
    "\n",
    "    def _build_topic_masks(self):\n",
    "        \"\"\"\n",
    "        Build a mask for each topic.\n",
    "        Each mask is a tensor of shape (vocab_size,) with 1.0 for token IDs that belong to the topic and 0.0 elsewhere.\n",
    "        \"\"\"\n",
    "        topic_masks = {}\n",
    "        for topic, words in self.topics_dict.items():\n",
    "            mask = torch.zeros(self.vocab_size)\n",
    "            for word in words:\n",
    "                # Tokenize the word without adding special tokens\n",
    "                token_ids = self.tokenizer.encode(word, add_special_tokens=False)\n",
    "                # Tokenize with space prefix (handles cases like 'word')\n",
    "                token_ids_with_space = self.tokenizer.encode(\" \" + word, add_special_tokens=False)\n",
    "                # In case the word is tokenized into multiple tokens, we mark all of them.\n",
    "                for token_id in token_ids:\n",
    "                    if token_id < self.vocab_size:  # Safety check\n",
    "                        mask[token_id] = 1.0/len(words)\n",
    "            topic_masks[topic] = mask\n",
    "        return topic_masks\n",
    "\n",
    "    def forward(self, logits):\n",
    "        \"\"\"\n",
    "        Compute the log probability that the generated tokens (given by logits) belong to each topic.\n",
    "\n",
    "        :param logits: Tensor of shape (batch_size, vocab_size)\n",
    "        :return: Dictionary mapping each topic to a tensor of log probabilities of shape (batch_size,)\n",
    "        \"\"\"\n",
    "        # Convert logits to probabilities.\n",
    "        #probs = F.softmax(logits, dim=-1)  # Shape: (batch_size, nb_tokens_sentence, vocab_size)\n",
    "        log_topic_probs = {}\n",
    "        \n",
    "        for topic, mask in self.topic_masks.items():\n",
    "            mask = mask.to(logits.device)\n",
    "            topic_sum = torch.sum(logits * mask.view(1, 1, -1), dim=-1)\n",
    "            #log_topic_prob = torch.log(torch.sum(topic_sum, dim=-1))\n",
    "            log_topic_probs[topic] = topic_sum\n",
    "        \n",
    "        return log_topic_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model = BoWAttributeModel(bow, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Probabilities for Phrase 1 (Science):\n",
      "Topic: science, Log Probability: tensor([[ -57.5548, -172.6336, -194.7263, -197.8066, -161.7631, -171.5723,\n",
      "         -160.1557, -147.8226, -130.2255, -141.1677, -156.4292]])\n",
      "Topic: legal, Log Probability: tensor([[ -54.3212, -164.2686, -184.2629, -187.7096, -154.2203, -163.4930,\n",
      "         -153.6130, -141.8147, -124.1180, -135.3927, -150.1185]])\n",
      "Topic: military, Log Probability: tensor([[ -52.8469, -159.1268, -178.4919, -182.2458, -149.7119, -158.7123,\n",
      "         -149.3137, -137.6028, -120.4733, -131.4070, -145.2930]])\n",
      "Topic: religion, Log Probability: tensor([[ -53.4345, -160.5638, -180.5462, -183.3576, -150.3586, -159.5904,\n",
      "         -150.3888, -138.7161, -122.8792, -132.6028, -147.0289]])\n",
      "Topic: computers, Log Probability: tensor([[ -45.8072, -136.8583, -153.0895, -155.9068, -128.5615, -135.6151,\n",
      "         -127.8420, -118.3433, -103.0042, -112.6249, -124.9898]])\n",
      "Topic: politics, Log Probability: tensor([[ -53.6490, -161.5672, -181.3701, -184.6495, -151.3493, -160.5775,\n",
      "         -150.8958, -139.6935, -122.2598, -133.3604, -147.2606]])\n",
      "Topic: space, Log Probability: tensor([[ -55.6596, -167.6555, -187.2944, -192.2742, -157.1387, -166.6856,\n",
      "         -155.7951, -143.7176, -126.0286, -137.5392, -151.1375]])\n",
      "Topic: positive_words, Log Probability: tensor([[-28.0932, -83.9701, -94.0815, -96.0581, -78.8111, -83.7582, -78.6591,\n",
      "         -72.4931, -63.6939, -69.3460, -76.5567]])\n",
      "Topic: fantasy, Log Probability: tensor([[ -58.2316, -175.8127, -197.0770, -201.7732, -165.5993, -175.4335,\n",
      "         -164.9958, -151.9604, -133.1131, -144.6706, -159.6826]])\n",
      "Topic: kitchen, Log Probability: tensor([[ -52.4009, -157.9469, -177.5703, -180.9673, -148.8670, -157.9739,\n",
      "         -148.1828, -137.2352, -120.1033, -130.4631, -143.6120]])\n",
      "\n",
      "Log Probabilities for Phrase 2 (Military):\n",
      "Topic: science, Log Probability: tensor([[ -61.1374, -168.3892, -195.4310, -208.9038, -212.3945, -204.1249,\n",
      "         -208.1662, -215.1500, -186.4787, -219.2880, -205.2886, -225.2820,\n",
      "         -211.1785, -213.6090, -206.0654, -154.7044, -121.2627, -228.5336,\n",
      "         -225.6954, -222.5395, -201.2394, -243.5759, -129.9598, -144.2498,\n",
      "         -206.0766, -205.6293]])\n",
      "Topic: legal, Log Probability: tensor([[ -57.4871, -159.1084, -184.8532, -198.2691, -202.5308, -193.9987,\n",
      "         -197.0668, -203.9749, -176.7658, -208.3069, -194.8757, -214.1694,\n",
      "         -199.6676, -202.3099, -195.4812, -146.8489, -115.8909, -217.0030,\n",
      "         -213.5112, -211.2476, -190.9339, -231.2551, -123.0811, -137.1170,\n",
      "         -195.3826, -195.1481]])\n",
      "Topic: military, Log Probability: tensor([[ -55.8480, -153.5774, -178.6061, -190.4678, -194.2944, -186.1687,\n",
      "         -189.9947, -196.3391, -169.9905, -200.8102, -187.5400, -206.1840,\n",
      "         -192.9940, -195.3458, -188.2315, -141.7364, -111.4127, -209.3179,\n",
      "         -206.1074, -203.7139, -183.7523, -222.9707, -119.3719, -132.3694,\n",
      "         -188.9544, -187.9224]])\n",
      "Topic: religion, Log Probability: tensor([[ -56.7210, -156.2118, -181.1129, -193.2549, -197.2793, -189.5022,\n",
      "         -192.9037, -198.9638, -173.1798, -203.6472, -190.7441, -208.8425,\n",
      "         -195.6058, -197.1486, -190.6765, -145.3885, -117.0778, -212.3414,\n",
      "         -209.1915, -206.8150, -187.0444, -226.3320, -122.1037, -138.3509,\n",
      "         -190.7987, -186.4485]])\n",
      "Topic: computers, Log Probability: tensor([[ -48.2947, -133.0092, -154.3364, -164.7973, -167.6865, -161.2603,\n",
      "         -164.0079, -169.6277, -147.1544, -173.1985, -161.8143, -177.9506,\n",
      "         -166.4149, -168.4175, -162.3413, -122.6157,  -95.7325, -179.8542,\n",
      "         -177.2902, -175.3021, -158.5719, -192.1748, -102.9900, -113.2565,\n",
      "         -162.4547, -160.9944]])\n",
      "Topic: politics, Log Probability: tensor([[ -56.8838, -156.6110, -181.8952, -195.0800, -199.1940, -191.5609,\n",
      "         -194.1369, -201.2691, -174.1703, -205.5643, -192.0644, -211.2935,\n",
      "         -197.1135, -199.5663, -192.8442, -144.7464, -114.6736, -213.9307,\n",
      "         -210.6350, -208.3292, -188.2300, -228.1007, -122.3878, -135.7940,\n",
      "         -192.8530, -191.8120]])\n",
      "Topic: space, Log Probability: tensor([[ -58.9504, -162.4599, -189.4608, -201.6550, -204.9196, -196.4438,\n",
      "         -199.8164, -206.9145, -180.6002, -211.4973, -198.0854, -217.3183,\n",
      "         -202.6515, -206.2807, -198.7610, -149.3013, -117.4102, -220.9386,\n",
      "         -217.7697, -215.5378, -194.9130, -236.0478, -125.8225, -140.7612,\n",
      "         -199.1061, -198.2064]])\n",
      "Topic: positive_words, Log Probability: tensor([[ -29.7140,  -81.6098,  -94.2408, -101.0339, -103.1917,  -99.0008,\n",
      "         -100.3409, -103.9863,  -90.2840, -106.2841,  -99.6637, -109.1496,\n",
      "         -101.8404, -103.2657,  -99.4436,  -75.0757,  -59.8411, -110.6658,\n",
      "         -108.7589, -107.6827,  -97.4734, -118.0922,  -63.4845,  -70.9090,\n",
      "          -99.7754,  -99.8982]])\n",
      "Topic: fantasy, Log Probability: tensor([[ -61.5738, -170.6177, -198.2176, -211.8788, -215.7649, -207.0878,\n",
      "         -210.5806, -218.3203, -189.9462, -222.8784, -208.7659, -228.7455,\n",
      "         -213.2052, -217.2878, -209.4146, -157.6939, -125.3242, -232.6886,\n",
      "         -229.3382, -226.9052, -205.2437, -247.9548, -132.6337, -147.7644,\n",
      "         -209.4091, -208.3513]])\n",
      "Topic: kitchen, Log Probability: tensor([[ -55.4117, -153.2431, -177.5492, -190.0393, -193.4705, -186.2310,\n",
      "         -189.9568, -195.7976, -169.8965, -200.5124, -187.4203, -206.2188,\n",
      "         -193.3161, -195.1045, -187.0130, -141.6162, -114.7704, -207.9472,\n",
      "         -205.2307, -202.6823, -183.1784, -221.9922, -118.2381, -134.8085,\n",
      "         -188.7532, -189.7950]])\n"
     ]
    }
   ],
   "source": [
    "phrase1 = \"The recent breakthrough in quantum physics has allowed scientists to explore new dimensions of energy and matter, potentially revolutionizing our understanding of the universe.\"\n",
    "phrase1 = \"climate control data electricity element energy evolution experiment fact flask fossil\"\n",
    "phrase2 = \"The military has deployed advanced drone technology to enhance surveillance and reconnaissance missions, providing real-time intelligence and improving strategic decision-making.\"\n",
    "\n",
    "# Encode the input text\n",
    "input_ids1 = tokenizer.encode(phrase1.lower(), return_tensors='pt').to(device)\n",
    "input_ids2 = tokenizer.encode(phrase2.lower(), return_tensors='pt').to(device)\n",
    "\n",
    "# Get logits from the model\n",
    "with torch.no_grad():\n",
    "    outputs1 = model(input_ids1)\n",
    "    outputs2 = model(input_ids2)\n",
    "    logits1 = outputs1.logits\n",
    "    logits2 = outputs2.logits\n",
    "\n",
    "# Compute log likelihoods for each topic\n",
    "log_probs1 = bow_model.forward(logits1)\n",
    "log_probs2 = bow_model.forward(logits2)\n",
    "\n",
    "# Print the log probabilities for each topic\n",
    "print(\"Log Probabilities for Phrase 1 (Science):\")\n",
    "for topic, log_prob in log_probs1.items():\n",
    "    print(f\"Topic: {topic}, Log Probability: {log_prob}\")\n",
    "\n",
    "print(\"\\nLog Probabilities for Phrase 2 (Military):\")\n",
    "for topic, log_prob in log_probs2.items():\n",
    "    print(f\"Topic: {topic}, Log Probability: {log_prob}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
